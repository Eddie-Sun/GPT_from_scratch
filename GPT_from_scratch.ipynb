{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMvRig8SkXAz2urX88PRA8M",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Eddie-Sun/GPT_from_scratch/blob/main/GPT_from_scratch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X_i2sFYqTD4S",
        "outputId": "19d380ab-4447-418d-9fb2-171f1c3e24f6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-12-22 19:29:01--  https://sherlock-holm.es/stories/plain-text/cano.txt\n",
            "Resolving sherlock-holm.es (sherlock-holm.es)... 157.90.249.21, 2a01:4f8:1c17:5725::1\n",
            "Connecting to sherlock-holm.es (sherlock-holm.es)|157.90.249.21|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 3868223 (3.7M) [text/plain]\n",
            "Saving to: ‘cano.txt’\n",
            "\n",
            "cano.txt            100%[===================>]   3.69M  4.34MB/s    in 0.8s    \n",
            "\n",
            "2023-12-22 19:29:02 (4.34 MB/s) - ‘cano.txt’ saved [3868223/3868223]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "#Training data: sherlock holmes - all stories\n",
        "!wget https://sherlock-holm.es/stories/plain-text/cano.txt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Read + inspect\n",
        "with open('cano.txt', 'r') as file:\n",
        "    text = file.read()\n",
        "\n",
        "print(\"length of file in char: \", len(text))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cekHcvB7YvoD",
        "outputId": "a603a55c-b4d6-4381-f8ec-267c25983e7f"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "length of file in char:  3868122\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chars = sorted(list(set(text)))\n",
        "vocab_size = len(chars)\n",
        "print(vocab_size)\n",
        "print(''.join(chars))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rh_nZKSvbIdT",
        "outputId": "4ac2c441-a5e5-4bc0-836b-1ad3b5758a8f"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "97\n",
            "\n",
            " !\"&'()*,-./0123456789:;?ABCDEFGHIJKLMNOPQRSTUVWXYZ[]`abcdefghijklmnopqrstuvwxyz£°½ßàâèéêîñôöûü’\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Create a mapping from characters to integers\n",
        "stoi = { ch:i for i, ch in enumerate(chars) }\n",
        "itos = { i:ch for i, ch in enumerate(chars) }\n",
        "encode = lambda s: [stoi[c] for c in s]\n",
        "decode = lambda l: ''.join([itos[i] for i in l])\n",
        "print(encode(\"hello there\"))\n",
        "print(decode(encode(\"hello there\")))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-oNt-fNvAYAW",
        "outputId": "44a4d05c-8de2-4c5c-e8a1-43be3b6f2d97"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[62, 59, 66, 66, 69, 1, 74, 62, 59, 72, 59]\n",
            "hello there\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Encode the text data into a tensor\n",
        "import torch\n",
        "data = torch.tensor(encode(text), dtype=torch.long)\n",
        "print(data.shape, data.dtype)\n",
        "print(data[:1000])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IN0AcW4bH92s",
        "outputId": "6f285772-aa9d-49ae-9aab-fecaa96a9473"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([3868122]) torch.int64\n",
            "tensor([ 0,  0,  0,  0,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
            "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1, 45, 33, 30,  1, 28, 40,\n",
            "        38, 41, 37, 30, 45, 30,  1, 44, 33, 30, 43, 37, 40, 28, 36,  1, 33, 40,\n",
            "        37, 38, 30, 44,  0,  0,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
            "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
            "         1, 26, 72, 74, 62, 75, 72,  1, 28, 69, 68, 55, 68,  1, 29, 69, 79, 66,\n",
            "        59,  0,  0,  0,  0,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
            "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
            "         1, 45, 55, 56, 66, 59,  1, 69, 60,  1, 57, 69, 68, 74, 59, 68, 74, 73,\n",
            "         0,  0,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1, 26,\n",
            "         1, 44, 74, 75, 58, 79,  1, 34, 68,  1, 44, 57, 55, 72, 66, 59, 74,  0,\n",
            "         0,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1, 45, 62,\n",
            "        59,  1, 44, 63, 61, 68,  1, 69, 60,  1, 74, 62, 59,  1, 31, 69, 75, 72,\n",
            "         0,  0,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
            "         1,  1, 45, 62, 59,  1, 26, 58, 76, 59, 68, 74, 75, 72, 59, 73,  1, 69,\n",
            "        60,  1, 44, 62, 59, 72, 66, 69, 57, 65,  1, 33, 69, 66, 67, 59, 73,  0,\n",
            "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1, 26,  1, 44,\n",
            "        57, 55, 68, 58, 55, 66,  1, 63, 68,  1, 27, 69, 62, 59, 67, 63, 55,  0,\n",
            "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1, 45, 62, 59,\n",
            "         1, 43, 59, 58, 10, 33, 59, 55, 58, 59, 58,  1, 37, 59, 55, 61, 75, 59,\n",
            "         0,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1, 26,  1,\n",
            "        28, 55, 73, 59,  1, 69, 60,  1, 34, 58, 59, 68, 74, 63, 74, 79,  0,  1,\n",
            "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1, 45, 62, 59,  1,\n",
            "        27, 69, 73, 57, 69, 67, 56, 59,  1, 47, 55, 66, 66, 59, 79,  1, 38, 79,\n",
            "        73, 74, 59, 72, 79,  0,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
            "         1,  1,  1, 45, 62, 59,  1, 31, 63, 76, 59,  1, 40, 72, 55, 68, 61, 59,\n",
            "         1, 41, 63, 70, 73,  0,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
            "         1,  1,  1, 45, 62, 59,  1, 38, 55, 68,  1, 77, 63, 74, 62,  1, 74, 62,\n",
            "        59,  1, 45, 77, 63, 73, 74, 59, 58,  1, 37, 63, 70,  0,  1,  1,  1,  1,\n",
            "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1, 45, 62, 59,  1, 26, 58, 76,\n",
            "        59, 68, 74, 75, 72, 59,  1, 69, 60,  1, 74, 62, 59,  1, 27, 66, 75, 59,\n",
            "         1, 28, 55, 72, 56, 75, 68, 57, 66, 59,  0,  1,  1,  1,  1,  1,  1,  1,\n",
            "         1,  1,  1,  1,  1,  1,  1,  1, 45, 62, 59,  1, 26, 58, 76, 59, 68, 74,\n",
            "        75, 72, 59,  1, 69, 60,  1, 74, 62, 59,  1, 44, 70, 59, 57, 65, 66, 59,\n",
            "        58,  1, 27, 55, 68, 58,  0,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
            "         1,  1,  1,  1, 45, 62, 59,  1, 26, 58, 76, 59, 68, 74, 75, 72, 59,  1,\n",
            "        69, 60,  1, 74, 62, 59,  1, 30, 68, 61, 63, 68, 59, 59, 72,  5, 73,  1,\n",
            "        45, 62, 75, 67, 56,  0,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
            "         1,  1,  1, 45, 62, 59,  1, 26, 58, 76, 59, 68, 74, 75, 72, 59,  1, 69,\n",
            "        60,  1, 74, 62, 59,  1, 39, 69, 56, 66, 59,  1, 27, 55, 57, 62, 59, 66,\n",
            "        69, 72,  0,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
            "        45, 62, 59,  1, 26, 58, 76, 59, 68, 74, 75, 72, 59,  1, 69, 60,  1, 74,\n",
            "        62, 59,  1, 27, 59, 72, 79, 66,  1, 28, 69, 72, 69, 68, 59, 74,  0,  1,\n",
            "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1, 45, 62, 59,  1,\n",
            "        26, 58, 76, 59, 68, 74, 75, 72, 59,  1, 69, 60,  1, 74, 62, 59,  1, 28,\n",
            "        69, 70, 70, 59, 72,  1, 27, 59, 59, 57, 62, 59, 73,  0,  0,  1,  1,  1,\n",
            "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1, 45, 62, 59,\n",
            "         1, 38, 59, 67, 69, 63, 72, 73,  1, 69, 60,  1, 44, 62, 59, 72, 66, 69,\n",
            "        57, 65,  1, 33, 69, 66, 67, 59, 73,  0,  1,  1,  1,  1,  1,  1,  1,  1,\n",
            "         1,  1,  1,  1,  1,  1,  1, 44, 63, 66, 76, 59, 72,  1, 27, 66, 55, 80,\n",
            "        59,  0,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1, 45,\n",
            "        62, 59,  1, 50, 59, 66, 66, 69, 77,  1, 31, 55, 57, 59,  0,  1,  1,  1,\n",
            "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1, 45, 62, 59,  1, 44, 74,\n",
            "        69, 57, 65, 10, 27, 72, 69, 65, 59, 72,  5, 73,  1, 28, 66, 59, 72, 65,\n",
            "         0,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1, 45, 62,\n",
            "        59,  1,  3, 32, 66, 69, 72, 63, 55,  1])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " - Tensors are multi-dimensional arrays used to store and operate on data within models.\n",
        " - Common dimensions of tensors in LLMs include:\n",
        "   - Batch Size: Number of sequences processed together for efficiency (1st dimension).\n",
        "   - Sequence Length: Number of tokens in each sequence (2nd dimension).\n",
        "   - Embedding Size: Size of the representation vectors for each token (3rd dimension).\n",
        "\n",
        " Example tensor shape for input data: [Batch Size, Sequence Length, Embedding Size]\n",
        " If processing 32 sequences, each with 128 tokens, and using 768-sized embeddings, shape is [32, 128, 768].\n",
        "\n",
        " - In attention mechanisms, you encounter 4-D tensors for attention scores:\n",
        "   - Shape: [Batch Size, Number of Attention Heads, Sequence Length, Sequence Length]\n",
        "\n",
        " - Output layer tensors often add a dimension for vocabulary size to represent token probabilities:\n",
        "   - Shape: [Batch Size, Sequence Length, Vocabulary Size]"
      ],
      "metadata": {
        "id": "90eNro4VHu8V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Split data into train and validation sets: help us understand how much model is overfitting\n",
        "n = int(0.9*len(data))\n",
        "train_data = data[:n]\n",
        "val_data = data[n:]"
      ],
      "metadata": {
        "id": "TOGHkaGuLs2h"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "block_size = 8\n",
        "train_data[:block_size + 1]"
      ],
      "metadata": {
        "id": "_WFNO79bMl1V",
        "outputId": "2c028fde-52c0-4eef-f44d-16d7a0c55c55",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0, 0, 0, 0, 1, 1, 1, 1, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(1137)\n",
        "batch_size = 4\n",
        "block_size = 8\n",
        "\n",
        "def get_batch(split):\n",
        "  data = train_data if split == 'train' else val_data\n",
        "  ix\n"
      ],
      "metadata": {
        "id": "jpe8lC1lNQjV",
        "outputId": "b7617138-07ec-4343-eff8-b89d8a596c47",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        }
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-13-40249809fd7d>\"\u001b[0;36m, line \u001b[0;32m5\u001b[0m\n\u001b[0;31m    def get_batch(split):\u001b[0m\n\u001b[0m                         ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m incomplete input\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "GFJVNQTQeDCF"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}